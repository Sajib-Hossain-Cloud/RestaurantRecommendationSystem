{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9b711b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "import pickle\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cea05d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (51717, 42)\n",
      "Columns: ['name', 'location', 'cuisines', 'rest_type', 'price_quality_ratio', 'popularity_score', 'quality_score', 'textblob_polarity', 'textblob_subjectivity', 'vote_density', 'votes', 'cluster_distance', 'avg_word_length', 'cuisines_target_encoded', 'review_length', 'cuisine_similarity_mean', 'cuisine_similarity_std', 'restaurant_cluster', 'sentiment_score', 'avg_sentence_length', 'word_count', 'sentence_count', 'positive_words', 'review_count', 'cuisines_count_encoded', 'rest_type_target_encoded', 'cost_clean', 'rest_type_count_encoded', 'cost_per_person', 'negative_words', 'location_similarity', 'has_detailed_review', 'location_count_encoded', 'location_popularity', 'location_target_encoded', 'book_table_binary', 'service_score', 'is_new_restaurant', 'cuisine_count', 'online_order_binary', 'cuisine_similarity_max', 'rating_clean']\n",
      "Sample restaurants: ['Jalsa', 'Spice Elephant', 'San Churro Cafe', 'Addhuri Udupi Bhojana', 'Grand Village']\n",
      "\n",
      "Missing values:\n",
      "293\n",
      "Data types:\n",
      "float64    21\n",
      "int64      17\n",
      "object      4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/sajibhossain/Desktop/RestaurantRecommendationSystem/app/ai_service/src/data/processed/processed_data.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"Sample restaurants: {df['name'].head().tolist()}\")\n",
    "\n",
    "# Check data quality\n",
    "print(f\"\\nMissing values:\")\n",
    "print(df.isnull().sum().sum())\n",
    "print(f\"Data types:\")\n",
    "print(df.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b9f0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 36 features for similarity calculation\n",
      "Feature matrix shape: (51717, 36)\n",
      "Memory usage: 7.10 MB\n",
      "Sample features: ['price_quality_ratio', 'popularity_score', 'quality_score', 'textblob_polarity', 'textblob_subjectivity', 'vote_density', 'cluster_distance', 'avg_word_length', 'cuisines_target_encoded', 'review_length']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def prepare_features_for_similarity(df):\n",
    "    \n",
    "    numerical_features = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    \n",
    "    exclude_features = ['rating_clean', 'votes'] \n",
    "    similarity_features = [col for col in numerical_features if col not in exclude_features]\n",
    "    \n",
    "    print(f\"Selected {len(similarity_features)} features for similarity calculation\")\n",
    "    \n",
    "    feature_matrix = df[similarity_features].copy()\n",
    "    \n",
    "    feature_matrix = feature_matrix.fillna(feature_matrix.median())\n",
    "    \n",
    "    feature_matrix = feature_matrix.astype(np.float32)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    feature_matrix_scaled = scaler.fit_transform(feature_matrix)\n",
    "    \n",
    "    feature_matrix_scaled = feature_matrix_scaled.astype(np.float32)\n",
    "    \n",
    "    return feature_matrix_scaled, similarity_features, scaler\n",
    "\n",
    "\n",
    "feature_matrix, similarity_features, scaler = prepare_features_for_similarity(df)\n",
    "\n",
    "print(f\"Feature matrix shape: {feature_matrix.shape}\")\n",
    "print(f\"Memory usage: {feature_matrix.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Sample features: {similarity_features[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b9fcbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature weights created:\n",
      "Restaurant characteristics weight: 0.38\n",
      "User review patterns weight: 0.35\n",
      "Quality & popularity weight: 0.21\n"
     ]
    }
   ],
   "source": [
    "def create_feature_weights(similarity_features):\n",
    "    \n",
    "    weights = {}\n",
    "    \n",
    "    restaurant_chars = [\n",
    "        'cuisine_similarity_mean', 'cuisine_similarity_max', 'cuisine_similarity_std',\n",
    "        'location_similarity', 'location_popularity',\n",
    "        'cost_clean', 'cost_per_person',\n",
    "        'rest_type_target_encoded', 'rest_type_count_encoded',\n",
    "        'service_score', 'online_order_binary', 'book_table_binary'\n",
    "    ]\n",
    "    \n",
    "    review_patterns = [\n",
    "        'sentiment_score', 'textblob_polarity', 'textblob_subjectivity',\n",
    "        'positive_words', 'negative_words',\n",
    "        'review_length', 'review_count', 'word_count', 'sentence_count',\n",
    "        'avg_sentence_length', 'avg_word_length', 'has_detailed_review'\n",
    "    ]\n",
    "    \n",
    "    quality_popularity = [\n",
    "        'quality_score', 'popularity_score', 'vote_density',\n",
    "        'restaurant_cluster', 'cluster_distance',\n",
    "        'price_quality_ratio', 'is_new_restaurant'\n",
    "    ]\n",
    "    \n",
    "    for feature in similarity_features:\n",
    "        if feature in restaurant_chars:\n",
    "            weights[feature] = 0.40 / len(restaurant_chars)\n",
    "        elif feature in review_patterns:\n",
    "            weights[feature] = 0.35 / len(review_patterns)\n",
    "        elif feature in quality_popularity:\n",
    "            weights[feature] = 0.25 / len(quality_popularity)\n",
    "        else:\n",
    "            weights[feature] = 0.01  \n",
    "    \n",
    "    return weights\n",
    "\n",
    "feature_weights = create_feature_weights(similarity_features)\n",
    "\n",
    "print(\"Feature weights created:\")\n",
    "print(f\"Restaurant characteristics weight: {sum([v for k, v in feature_weights.items() if 'cuisine' in k or 'location' in k or 'cost' in k or 'rest_type' in k or 'service' in k]):.2f}\")\n",
    "print(f\"User review patterns weight: {sum([v for k, v in feature_weights.items() if 'sentiment' in k or 'textblob' in k or 'positive' in k or 'negative' in k or 'review' in k or 'word' in k or 'sentence' in k]):.2f}\")\n",
    "print(f\"Quality & popularity weight: {sum([v for k, v in feature_weights.items() if 'quality' in k or 'popularity' in k or 'cluster' in k or 'price' in k]):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da0778d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating similarity matrix for 51717 restaurants...\n",
      "Processing chunk 1/52\n",
      "Processing chunk 2/52\n",
      "Processing chunk 3/52\n",
      "Processing chunk 4/52\n",
      "Processing chunk 5/52\n",
      "Processing chunk 6/52\n",
      "Processing chunk 7/52\n",
      "Processing chunk 8/52\n",
      "Processing chunk 9/52\n",
      "Processing chunk 10/52\n",
      "Processing chunk 11/52\n",
      "Processing chunk 12/52\n",
      "Processing chunk 13/52\n",
      "Processing chunk 14/52\n",
      "Processing chunk 15/52\n",
      "Processing chunk 16/52\n",
      "Processing chunk 17/52\n",
      "Processing chunk 18/52\n",
      "Processing chunk 19/52\n",
      "Processing chunk 20/52\n",
      "Processing chunk 21/52\n",
      "Processing chunk 22/52\n",
      "Processing chunk 23/52\n",
      "Processing chunk 24/52\n",
      "Processing chunk 25/52\n",
      "Processing chunk 26/52\n",
      "Processing chunk 27/52\n",
      "Processing chunk 28/52\n",
      "Processing chunk 29/52\n",
      "Processing chunk 30/52\n",
      "Processing chunk 31/52\n",
      "Processing chunk 32/52\n",
      "Processing chunk 33/52\n",
      "Processing chunk 34/52\n",
      "Processing chunk 35/52\n",
      "Processing chunk 36/52\n",
      "Processing chunk 37/52\n",
      "Processing chunk 38/52\n",
      "Processing chunk 39/52\n",
      "Processing chunk 40/52\n",
      "Processing chunk 41/52\n",
      "Processing chunk 42/52\n",
      "Processing chunk 43/52\n",
      "Processing chunk 44/52\n",
      "Processing chunk 45/52\n",
      "Processing chunk 46/52\n",
      "Processing chunk 47/52\n",
      "Processing chunk 48/52\n",
      "Processing chunk 49/52\n",
      "Processing chunk 50/52\n",
      "Processing chunk 51/52\n",
      "Processing chunk 52/52\n",
      "Similarity matrix shape: (51717, 51717)\n",
      "Memory usage: 10202.97 MB\n",
      "Similarity range: -0.849 to 1.000\n",
      "Average similarity: 0.008\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def create_similarity_matrix_chunked(feature_matrix, feature_weights, similarity_features, chunk_size=1000):\n",
    "    \"\"\"Create similarity matrix in chunks to avoid memory issues\"\"\"\n",
    "    \n",
    "    n_restaurants = feature_matrix.shape[0]\n",
    "    print(f\"Creating similarity matrix for {n_restaurants} restaurants...\")\n",
    "    \n",
    "    weighted_matrix = feature_matrix.copy()\n",
    "    for i, feature in enumerate(similarity_features):\n",
    "        if feature in feature_weights:\n",
    "            weighted_matrix[:, i] *= feature_weights[feature]\n",
    "    \n",
    "    similarity_matrix = np.zeros((n_restaurants, n_restaurants), dtype=np.float32)\n",
    "    \n",
    "    for i in range(0, n_restaurants, chunk_size):\n",
    "        end_i = min(i + chunk_size, n_restaurants)\n",
    "        print(f\"Processing chunk {i//chunk_size + 1}/{(n_restaurants + chunk_size - 1)//chunk_size}\")\n",
    "        \n",
    "        for j in range(0, n_restaurants, chunk_size):\n",
    "            end_j = min(j + chunk_size, n_restaurants)\n",
    "            \n",
    "            chunk_similarity = cosine_similarity(\n",
    "                weighted_matrix[i:end_i], \n",
    "                weighted_matrix[j:end_j]\n",
    "            )\n",
    "            \n",
    "            similarity_matrix[i:end_i, j:end_j] = chunk_similarity\n",
    "    \n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = create_similarity_matrix_chunked(feature_matrix, feature_weights, similarity_features)\n",
    "\n",
    "print(f\"Similarity matrix shape: {similarity_matrix.shape}\")\n",
    "print(f\"Memory usage: {similarity_matrix.nbytes / 1024 / 1024:.2f} MB\")\n",
    "print(f\"Similarity range: {similarity_matrix.min():.3f} to {similarity_matrix.max():.3f}\")\n",
    "print(f\"Average similarity: {similarity_matrix.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4574c01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurant recommender initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class RestaurantRecommender:\n",
    "    def __init__(self, df, similarity_matrix, feature_weights, similarity_features):\n",
    "        self.df = df\n",
    "        self.similarity_matrix = similarity_matrix\n",
    "        self.feature_weights = feature_weights\n",
    "        self.similarity_features = similarity_features\n",
    "        self.restaurant_names = df['name'].tolist()\n",
    "        \n",
    "        self.name_to_index = {name: idx for idx, name in enumerate(self.restaurant_names)}\n",
    "        self.index_to_name = {idx: name for name, idx in self.name_to_index.items()}\n",
    "    \n",
    "    def find_restaurant_index(self, restaurant_name):\n",
    "        \"\"\"Find restaurant index by name (with fuzzy matching)\"\"\"\n",
    "        if restaurant_name in self.name_to_index:\n",
    "            return self.name_to_index[restaurant_name]\n",
    "        \n",
    "        for name in self.restaurant_names:\n",
    "            if restaurant_name.lower() in name.lower() or name.lower() in restaurant_name.lower():\n",
    "                return self.name_to_index[name]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def get_similarity_explanation(self, restaurant1_idx, restaurant2_idx):\n",
    "        \"\"\"Generate explanation for why restaurants are similar\"\"\"\n",
    "        restaurant1 = self.df.iloc[restaurant1_idx]\n",
    "        restaurant2 = self.df.iloc[restaurant2_idx]\n",
    "        \n",
    "        explanations = []\n",
    "        \n",
    "        if restaurant1['cuisines'] == restaurant2['cuisines']:\n",
    "            explanations.append(f\"Same cuisines: {restaurant1['cuisines']}\")\n",
    "        \n",
    "        if restaurant1['location'] == restaurant2['location']:\n",
    "            explanations.append(f\"Same location: {restaurant1['location']}\")\n",
    "        \n",
    "        cost_diff = abs(restaurant1['cost_clean'] - restaurant2['cost_clean'])\n",
    "        if cost_diff < 100:\n",
    "            explanations.append(f\"Similar cost range: ₹{restaurant1['cost_clean']:.0f} vs ₹{restaurant2['cost_clean']:.0f}\")\n",
    "        \n",
    "        rating_diff = abs(restaurant1['rating_clean'] - restaurant2['rating_clean'])\n",
    "        if rating_diff < 0.5:\n",
    "            explanations.append(f\"Similar ratings: {restaurant1['rating_clean']:.1f} vs {restaurant2['rating_clean']:.1f}\")\n",
    "        \n",
    "        if restaurant1['rest_type'] == restaurant2['rest_type']:\n",
    "            explanations.append(f\"Same restaurant type: {restaurant1['rest_type']}\")\n",
    "        \n",
    "        return explanations\n",
    "    \n",
    "    def recommend_restaurants(self, restaurant_name, top_n=10, min_similarity=0.3):\n",
    "        \"\"\"Main recommendation function\"\"\"\n",
    "        \n",
    "        restaurant_idx = self.find_restaurant_index(restaurant_name)\n",
    "        \n",
    "        if restaurant_idx is None:\n",
    "            return {\n",
    "                'error': f'Restaurant \"{restaurant_name}\" not found in dataset',\n",
    "                'suggestions': self.restaurant_names[:5]\n",
    "            }\n",
    "        \n",
    "        restaurant_similarities = self.similarity_matrix[restaurant_idx]\n",
    "        \n",
    "        similar_indices = np.argsort(restaurant_similarities)[::-1][1:top_n+1]\n",
    "        similar_scores = restaurant_similarities[similar_indices]\n",
    "        \n",
    "        valid_indices = similar_indices[similar_scores >= min_similarity]\n",
    "        valid_scores = similar_scores[similar_scores >= min_similarity]\n",
    "        \n",
    "        if len(valid_indices) == 0:\n",
    "            return {\n",
    "                'error': f'No similar restaurants found for \"{restaurant_name}\" with similarity >= {min_similarity}',\n",
    "                'restaurant_name': restaurant_name\n",
    "            }\n",
    "        \n",
    "        recommendations = []\n",
    "        for idx, score in zip(valid_indices, valid_scores):\n",
    "            restaurant_data = self.df.iloc[idx]\n",
    "            explanations = self.get_similarity_explanation(restaurant_idx, idx)\n",
    "            \n",
    "            recommendation = {\n",
    "                'name': restaurant_data['name'],\n",
    "                'similarity_score': float(score),\n",
    "                'location': restaurant_data['location'],\n",
    "                'cuisines': restaurant_data['cuisines'],\n",
    "                'cost_for_two': f\"₹{restaurant_data['cost_clean']:.0f}\",\n",
    "                'rating': float(restaurant_data['rating_clean']) if pd.notna(restaurant_data['rating_clean']) else None,\n",
    "                'restaurant_type': restaurant_data['rest_type'],\n",
    "                'online_order': restaurant_data['online_order'],\n",
    "                'book_table': restaurant_data['book_table'],\n",
    "                'why_similar': explanations\n",
    "            }\n",
    "            recommendations.append(recommendation)\n",
    "        \n",
    "        return {\n",
    "            'input_restaurant': self.df.iloc[restaurant_idx]['name'],\n",
    "            'recommendations': recommendations,\n",
    "            'total_recommendations': len(recommendations)\n",
    "        }\n",
    "\n",
    "\n",
    "recommender = RestaurantRecommender(df, similarity_matrix, feature_weights, similarity_features)\n",
    "print(\"Restaurant recommender initialized successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef7f4c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving similarity matrix...\n",
      "Saved top-20 similarities as JSON\n",
      "Model training completed and saved successfully!\n",
      "\n",
      "Files created:\n",
      "- models/restaurant_recommender.pkl (main model)\n",
      "- models/similarity_matrix.npy (efficient numpy format)\n",
      "- models/similarity_matrix_compressed.npz (compressed numpy)\n",
      "- models/top_k_similarities.json (top-20 similarities - recommended)\n",
      "- models/restaurant_data.csv (restaurant data)\n",
      "- models/feature_weights.json (feature weights)\n",
      "- models/training_summary.json (training summary)\n",
      "\n",
      "Training Summary:\n",
      "Total restaurants: 51717\n",
      "Total features: 36\n",
      "Similarity matrix shape: (51717, 51717)\n",
      "Average similarity: 0.008\n",
      "Memory usage: 10202.97 MB\n",
      "File sizes: .npy=10203.0MB, .json=7.5MB\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "model_data = {\n",
    "    'feature_weights': feature_weights,\n",
    "    'similarity_features': similarity_features,\n",
    "    'restaurant_names': df['name'].tolist(),\n",
    "    'df_columns': df.columns.tolist(),\n",
    "    'feature_matrix_shape': feature_matrix.shape,\n",
    "    'scaler': scaler\n",
    "}\n",
    "\n",
    "with open('models/restaurant_recommender.pkl', 'wb') as f:\n",
    "    pickle.dump(model_data, f)\n",
    "\n",
    "print(\"Saving similarity matrix...\")\n",
    "\n",
    "np.save('models/similarity_matrix.npy', similarity_matrix)\n",
    "\n",
    "np.savez_compressed('models/similarity_matrix_compressed.npz', similarity_matrix)\n",
    "\n",
    "def save_top_k_similarities(similarity_matrix, restaurant_names, k=20):\n",
    "    \"\"\"Save only top-K similar restaurants for each restaurant\"\"\"\n",
    "    top_k_data = {}\n",
    "    \n",
    "    for i, restaurant_name in enumerate(restaurant_names):\n",
    "        similarities = similarity_matrix[i]\n",
    "        \n",
    "        top_indices = np.argsort(similarities)[::-1][1:k+1]  \n",
    "        top_similarities = similarities[top_indices]\n",
    "        \n",
    "        top_k_data[restaurant_name] = {\n",
    "            'similar_restaurants': [restaurant_names[j] for j in top_indices],\n",
    "            'similarity_scores': top_similarities.tolist()\n",
    "        }\n",
    "    \n",
    "    with open('models/top_k_similarities.json', 'w') as f:\n",
    "        json.dump(top_k_data, f)\n",
    "    \n",
    "    return top_k_data\n",
    "\n",
    "top_k_data = save_top_k_similarities(similarity_matrix, df['name'].tolist(), k=20)\n",
    "print(\"Saved top-20 similarities as JSON\")\n",
    "\n",
    "df.to_csv('models/restaurant_data.csv', index=False)\n",
    "\n",
    "with open('models/feature_weights.json', 'w') as f:\n",
    "    json.dump(feature_weights, f, indent=2)\n",
    "\n",
    "training_summary = {\n",
    "    'total_restaurants': len(df),\n",
    "    'total_features': len(similarity_features),\n",
    "    'similarity_matrix_shape': similarity_matrix.shape,\n",
    "    'feature_categories': {\n",
    "        'restaurant_characteristics': len([f for f in similarity_features if 'cuisine' in f or 'location' in f or 'cost' in f or 'rest_type' in f or 'service' in f]),\n",
    "        'user_review_patterns': len([f for f in similarity_features if 'sentiment' in f or 'textblob' in f or 'positive' in f or 'negative' in f or 'review' in f or 'word' in f or 'sentence' in f]),\n",
    "        'quality_popularity': len([f for f in similarity_features if 'quality' in f or 'popularity' in f or 'cluster' in f or 'price' in f])\n",
    "    },\n",
    "    'similarity_stats': {\n",
    "        'min_similarity': float(similarity_matrix.min()),\n",
    "        'max_similarity': float(similarity_matrix.max()),\n",
    "        'mean_similarity': float(similarity_matrix.mean()),\n",
    "        'std_similarity': float(similarity_matrix.std())\n",
    "    },\n",
    "    'memory_usage_mb': {\n",
    "        'feature_matrix': feature_matrix.nbytes / 1024 / 1024,\n",
    "        'similarity_matrix': similarity_matrix.nbytes / 1024 / 1024\n",
    "    },\n",
    "    'file_sizes_mb': {\n",
    "        'similarity_matrix_npy': os.path.getsize('models/similarity_matrix.npy') / 1024 / 1024 if os.path.exists('models/similarity_matrix.npy') else 0,\n",
    "        'top_k_similarities_json': os.path.getsize('models/top_k_similarities.json') / 1024 / 1024 if os.path.exists('models/top_k_similarities.json') else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('models/training_summary.json', 'w') as f:\n",
    "    json.dump(training_summary, f, indent=2)\n",
    "\n",
    "print(\"Model training completed and saved successfully!\")\n",
    "print(\"\\nFiles created:\")\n",
    "print(\"- models/restaurant_recommender.pkl (main model)\")\n",
    "print(\"- models/similarity_matrix.npy (efficient numpy format)\")\n",
    "print(\"- models/similarity_matrix_compressed.npz (compressed numpy)\")\n",
    "print(\"- models/top_k_similarities.json (top-20 similarities - recommended)\")\n",
    "print(\"- models/restaurant_data.csv (restaurant data)\")\n",
    "print(\"- models/feature_weights.json (feature weights)\")\n",
    "print(\"- models/training_summary.json (training summary)\")\n",
    "\n",
    "print(f\"\\nTraining Summary:\")\n",
    "print(f\"Total restaurants: {training_summary['total_restaurants']}\")\n",
    "print(f\"Total features: {training_summary['total_features']}\")\n",
    "print(f\"Similarity matrix shape: {training_summary['similarity_matrix_shape']}\")\n",
    "print(f\"Average similarity: {training_summary['similarity_stats']['mean_similarity']:.3f}\")\n",
    "print(f\"Memory usage: {training_summary['memory_usage_mb']['similarity_matrix']:.2f} MB\")\n",
    "print(f\"File sizes: .npy={training_summary['file_sizes_mb']['similarity_matrix_npy']:.1f}MB, .json={training_summary['file_sizes_mb']['top_k_similarities_json']:.1f}MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e11b93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quick Model Validation:\n",
      "Successfully tested 3 restaurants\n",
      "- Pizza Hut: 3 recommendations, avg similarity: 0.950\n",
      "- McDonald's: 3 recommendations, avg similarity: 0.953\n",
      "- KFC: 3 recommendations, avg similarity: 0.838\n",
      "Model validation successful!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def quick_validation():\n",
    "    \"\"\"Quick validation of the trained model\"\"\"\n",
    "    \n",
    "    test_restaurants = ['Pizza Hut', 'McDonald\\'s', 'KFC']\n",
    "    validation_results = []\n",
    "    \n",
    "    for restaurant in test_restaurants:\n",
    "        try:\n",
    "            result = recommender.recommend_restaurants(restaurant, top_n=3)\n",
    "            if 'error' not in result:\n",
    "                validation_results.append({\n",
    "                    'restaurant': restaurant,\n",
    "                    'recommendations_found': result['total_recommendations'],\n",
    "                    'avg_similarity': np.mean([rec['similarity_score'] for rec in result['recommendations']])\n",
    "                })\n",
    "            else:\n",
    "                print(f\"Error: {restaurant}: {result['error']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {restaurant}: {e}\")\n",
    "    \n",
    "    print(\"Quick Model Validation:\")\n",
    "    print(f\"Successfully tested {len(validation_results)} restaurants\")\n",
    "    for result in validation_results:\n",
    "        print(f\"- {result['restaurant']}: {result['recommendations_found']} recommendations, avg similarity: {result['avg_similarity']:.3f}\")\n",
    "    \n",
    "    if len(validation_results) > 0:\n",
    "        print(\"Model validation successful!\")\n",
    "    else:\n",
    "        print(\"Model validation failed. Check for issues.\")\n",
    "\n",
    "def recommend_restaurants_fixed(self, restaurant_name, top_n=10, min_similarity=0.3):\n",
    "    \n",
    "    restaurant_idx = self.find_restaurant_index(restaurant_name)\n",
    "    \n",
    "    if restaurant_idx is None:\n",
    "        return {\n",
    "            'error': f'Restaurant \"{restaurant_name}\" not found in dataset',\n",
    "            'suggestions': self.restaurant_names[:5]\n",
    "        }\n",
    "    \n",
    "    restaurant_similarities = self.similarity_matrix[restaurant_idx]\n",
    "    \n",
    "    similar_indices = np.argsort(restaurant_similarities)[::-1][1:top_n+1]\n",
    "    similar_scores = restaurant_similarities[similar_indices]\n",
    "    \n",
    "    valid_indices = similar_indices[similar_scores >= min_similarity]\n",
    "    valid_scores = similar_scores[similar_scores >= min_similarity]\n",
    "    \n",
    "    if len(valid_indices) == 0:\n",
    "        return {\n",
    "            'error': f'No similar restaurants found for \"{restaurant_name}\" with similarity >= {min_similarity}',\n",
    "            'restaurant_name': restaurant_name\n",
    "        }\n",
    "    \n",
    "    recommendations = []\n",
    "    for idx, score in zip(valid_indices, valid_scores):\n",
    "        restaurant_data = self.df.iloc[idx]\n",
    "        \n",
    "        recommendation = {\n",
    "            'name': restaurant_data['name'],\n",
    "            'similarity_score': float(score),\n",
    "            'location': restaurant_data['location'],\n",
    "            'cuisines': restaurant_data['cuisines'],\n",
    "            'cost_for_two': f\"₹{restaurant_data['cost_clean']:.0f}\",\n",
    "            'rating': float(restaurant_data['rating_clean']) if pd.notna(restaurant_data['rating_clean']) else None,\n",
    "            'restaurant_type': restaurant_data['rest_type'],\n",
    "            'online_order': restaurant_data['online_order_binary'],  \n",
    "            'book_table': restaurant_data['book_table_binary'],      \n",
    "            'why_similar': self.get_similarity_explanation(restaurant_idx, idx)\n",
    "        }\n",
    "        recommendations.append(recommendation)\n",
    "    \n",
    "    return {\n",
    "        'input_restaurant': self.df.iloc[restaurant_idx]['name'],\n",
    "        'recommendations': recommendations,\n",
    "        'total_recommendations': len(recommendations)\n",
    "    }\n",
    "\n",
    "recommender.recommend_restaurants = recommend_restaurants_fixed.__get__(recommender, RestaurantRecommender)\n",
    "\n",
    "quick_validation()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
